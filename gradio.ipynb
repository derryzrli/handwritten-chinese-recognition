{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e5d391b-069b-4710-ba71-a9ef912369cc",
   "metadata": {},
   "source": [
    "# Now we build a handwriting recognition app to apply our model for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebbb6c34-b19f-4615-a432-271d8aad9ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e72b42-a294-4ef9-a6ce-90efd0de3941",
   "metadata": {},
   "source": [
    "## Load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b4a22f-811f-4fa3-8954-30ac4eaebc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url_xwzj = '/Users/derryzrli/Downloads/data_dsi_capstone/traditional_chinese_training_data_xwzj/CNN_model_xwzj.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a59be02-322c-463f-afb9-92e92e0c2b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-12 18:22:33.509485: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(model_url_xwzj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92c3bb1-2e71-40d6-815c-a81daad9618d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '境', 1: '學', 2: '止', 3: '無'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_map = {'境': 0, '學': 1, '止': 2, '無': 3}\n",
    "class_map = {val:key for key, val in class_map.items()}\n",
    "class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e418892-7845-4e24-b591-5ddd537fd6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-12 18:22:42.465404: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'止': 0.8266451358795166, '無': 0.15484075248241425, '境': 0.01700018160045147}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img = Image.open('/Users/derryzrli/Downloads/data_dsi_capstone/traditional_chinese_training_data/止/止_11.png')\n",
    "img = np.array(img)/255.\n",
    "img = tf.image.resize(img, [50,50])\n",
    "img = img.numpy()\n",
    "img = img.reshape(1 ,50, 50, 3) # 1 observation, 50 px high, 50 px wide, 3 depth\n",
    "pred = model.predict(img)\n",
    "values, indices = tf.math.top_k(pred[0], 3)\n",
    "confidences = {class_map[i.numpy()]: float(v.numpy()) for i, v in zip(indices, values)}\n",
    "confidences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6094f250-4654-40bf-9153-672bcee6c8d6",
   "metadata": {},
   "source": [
    "## Make Classify Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "691f72b4-ae68-438c-8645-3fda7beb7a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(img):\n",
    "    # img = img.reshape(28, 28, 1)\n",
    "    # x = tf.image.grayscale_to_rgb(tf.convert_to_tensor(img)).numpy()\n",
    "    x = np.array(img)/255.\n",
    "\n",
    "    x = tf.image.resize(x, [50,50]).numpy()\n",
    "    x = x.reshape(1, 50, 50, 3)\n",
    "    pred = model.predict(x)\n",
    "    values, indices = tf.math.top_k(pred[0], 3)\n",
    "    confidences = {class_map[i.numpy()]: float(v.numpy()) for i, v in zip(indices, values)}\n",
    "    return confidences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7807a50-fa8c-4c09-bff1-1510b626f206",
   "metadata": {},
   "source": [
    "## Instantiate Gradio App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "188c43b6-095b-4793-b028-2cbd9683b574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derryzrli/opt/anaconda3/envs/tfm1/lib/python3.9/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/Users/derryzrli/opt/anaconda3/envs/tfm1/lib/python3.9/site-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861/\n",
      "Running on public URL: https://58017.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://58017.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7f85d81d4760>,\n",
       " 'http://127.0.0.1:7861/',\n",
       " 'https://58017.gradio.app')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback None(<Task finishe...> result=None>)\n",
      "handle: <Handle>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/derryzrli/opt/anaconda3/envs/tfm1/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "TypeError: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "gr.Interface(fn=classify, \n",
    "             inputs=gr.inputs.Image(),\n",
    "             outputs=gr.outputs.Label(num_top_classes=3),\n",
    "             examples=['derry_chinese_handwriting/wu_1.png', 'derry_chinese_handwriting/wu_2.png', 'derry_chinese_handwriting/wu_3.png', \n",
    "                      'derry_chinese_handwriting/zhi_1.png', 'derry_chinese_handwriting/zhi_3.png', 'derry_chinese_handwriting/zhi_2.png']).launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cc5df8-a497-4440-9f94-14541f50dbf8",
   "metadata": {},
   "source": [
    "## Viola~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
